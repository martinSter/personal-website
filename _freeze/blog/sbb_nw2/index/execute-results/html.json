{
  "hash": "eb9ead8404fea7be047d0ef21dd26413",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"SBB Network Analysis - Part 2\"\nauthor:\n  - name: Martin Sterchi\n    email: martin.sterchi@fhnw.ch\ndate: 2025-03-31\ncategories: [\"Networks\"]\nimage: sbb_hb.jpg\nformat:\n  html:\n    df-print: paged\n    toc: true\ngoogle-scholar: false\n---\n\n\n\n\nIn [Part 1](../sbb_nw/index.qmd) of this series on the Swiss train network, I demonstrated how to construct a directed network where nodes represent stations, and a directed edge exists whenever at least one nonstop train connection links two stations.\n\nFor some time, I believed this was the most intuitive graph representation for this context. However, after reading an insightful 2006 paper by [Maciej Kurant and Patrick Thiran](https://arxiv.org/abs/physics/0510151), I discovered that public transport networks can be represented in (at least) three distinct ways. The graph representation I introduced in [Part 1](../sbb_nw/index.qmd) aligns with what they call the **space-of-stops** representation.\n\nYet, depending on the specific questions being asked, two other graph representations can also be useful. In the **space-of-changes** representation proposed by Kurant and Thiran (2006), an edge exists between any two stations connected by a train on a given \"Fahrt\", even if the train makes stops at other stations in between.\n\nThe third representation, **space-of-stations**, includes an undirected edge between two stations only if they are directly connected by railway tracks, with no other station in between. This approach offers a more infrastructure-focused perspective on the network.\n\nCrucially, all three representations share the same set of nodes—namely, all active train stations. What differs is how the edges are defined.\n\nKurant and Thiran (2006) also highlight how the shortest path length is interpreted differently in each representation:\n\n-   *space-of-stops*: The number of train stops on a journey between two stations.\n-   *space-of-changes*: The number of times a traveler must change trains between two stations.\n-   *space-of-stations*: The number of stations passed through between two stations.\n\nLastly, they point out an important subgraph relationship among these representations: *space-of-stations* is a subgraph of *space-of-stops*, which in turn is a subgraph of *space-of-changes*.\n\nAs always, we begin the practical part with loading the libraries we are going to use.\n\n::: {#ecd03802 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nfrom collections import Counter, defaultdict\n\n# Check versions of libraries.\nprint(\"Pandas version:\", pd.__version__)\n\n# Make sure there is no limit on the number of columns shown.\npd.set_option('display.max_columns', None)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPandas version: 2.1.4\n```\n:::\n:::\n\n\nWe first present how the *space-of-changes* representation can be extracted. After that we show one way of finding the edges for the *space-of-stations* representation.\n\n### Space-of-changes\n\nWe start by importing the already processed \"Ist-Daten\" from [Part 1](../sbb_nw/index.qmd). Since we load them from a CSV file we have to transform all date-time information into the Pandas datetime format.\n\n::: {#930b5fff .cell execution_count=2}\n``` {.python .cell-code}\n# Load the processed IST-DATEN.\ndf = pd.read_csv('ist-daten.csv', low_memory=False)\n\n# Convert BETRIEBSTAG to date format\ndf['BETRIEBSTAG'] = pd.to_datetime(df['BETRIEBSTAG'])\n\n# Convert ANKUNFTSZEIT, AN_PROGNOSE, ABFAHRTSZEIT, AB_PROGNOSE to datetime format\ndf['ANKUNFTSZEIT'] = pd.to_datetime(df['ANKUNFTSZEIT'])\ndf['AN_PROGNOSE'] = pd.to_datetime(df['AN_PROGNOSE'])\ndf['ABFAHRTSZEIT'] = pd.to_datetime(df['ABFAHRTSZEIT'])\ndf['AB_PROGNOSE'] = pd.to_datetime(df['AB_PROGNOSE'])\n```\n:::\n\n\nNext comes the key part of extracting the edges for the *space-of-changes* representation. We will group the rows by `FAHRT_BEZEICHNER`. Then, we will use two nested loops to create edges between any station and all subsequent stations on a given \"Fahrt\". Note that in contrast to Kurant and Thiran (2006) we will extract *directed* edges. The following function specifies how the edges can be extracted for one group. It's not very performant code and there may be smarter and more efficient ways of doing this. But it does the job.\n\n::: {#13e8980e .cell execution_count=3}\n``` {.python .cell-code}\n# Function to compute (directed) edges according to spaces-of-changes principle.\ndef get_edges_in_groups(group):\n    # Empty list for results of a group.\n    results = []\n    # Loop over all rows in group.\n    for i in range(len(group)):\n        # Nested loop over all subsequent rows.\n        for j in range(i + 1, len(group)):\n            # Now, append edge to results list.\n            results.append((\n                group.iloc[i][\"STATION_NAME\"], # Station of origin\n                group.iloc[j][\"STATION_NAME\"], # Station of destination\n                (group.iloc[j]['ANKUNFTSZEIT'] - group.iloc[i]['ABFAHRTSZEIT']).total_seconds() / 60 # Time (minutes)\n            ))\n    # Return list.\n    return results\n```\n:::\n\n\nWe can now apply that function to every group. On my machine, this step took roughly 10 minutes.\n\n::: {#dd56659b .cell execution_count=4}\n``` {.python .cell-code}\n# Now apply that function group-wise.\nedges_series = df.groupby(\"FAHRT_BEZEICHNER\", group_keys=False).apply(get_edges_in_groups)\n```\n:::\n\n\nThe output of the previous step is a Pandas series, as the following check confirms. We can see that every element of that series is identified with `FAHRT_BEZEICHNER` and contains a list with the edges, also including the time between the two nodes.\n\n::: {#1b900161 .cell execution_count=5}\n``` {.python .cell-code}\n# Make sure the result is a pandas series.\nprint(\"Is pandas series:\", isinstance(edges_series, pd.Series))\n\n# Check first few elements:\nedges_series.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIs pandas series: True\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\nFAHRT_BEZEICHNER\n60402-NZ-8503000-213400    [(Zürich HB, Basel SBB, 54.0), (Zürich HB, Bas...\n60403-NZ-8400058-191500    [(Basel Bad Bf, Basel SBB, 7.0), (Basel Bad Bf...\n60408-NZ-8098160-205700    [(Basel Bad Bf, Basel SBB, 8.0), (Basel Bad Bf...\n60409-NZ-8503000-195900    [(Zürich HB, Basel SBB, 54.0), (Zürich HB, Bas...\n60470-NZ-8503000-205900    [(Zürich HB, Basel SBB, 54.0), (Zürich HB, Bas...\ndtype: object\n```\n:::\n:::\n\n\nWe perform another quick check to make sure the series contains as many elements as there are unique `FAHRT_BEZEICHNER` strings. That seems to be the case.\n\n::: {#defb4c18 .cell execution_count=6}\n``` {.python .cell-code}\n# How many elements?\nprint(\"Number of elements in series:\", len(edges_series))\n\n# Is that the number of distinct FAHRTEN?\ndf[['FAHRT_BEZEICHNER']].nunique()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of elements in series: 14653\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nFAHRT_BEZEICHNER    14653\ndtype: int64\n```\n:::\n:::\n\n\nWe quickly check the list of edges for one \"Fahrt\" to make sure it really extracted the edges in the right way.\n\n::: {#731a82ac .cell execution_count=7}\n``` {.python .cell-code}\n# Let's check out one FAHRT.\nedges_series[\"85:97:9:000\"]\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n[('Yverdon-les-Bains', 'Vuiteboeuf', 10.0),\n ('Yverdon-les-Bains', 'Baulmes', 14.0),\n ('Yverdon-les-Bains', 'Six-Fontaines', 18.0),\n ('Yverdon-les-Bains', 'Ste-Croix', 33.0),\n ('Vuiteboeuf', 'Baulmes', 4.0),\n ('Vuiteboeuf', 'Six-Fontaines', 8.0),\n ('Vuiteboeuf', 'Ste-Croix', 23.0),\n ('Baulmes', 'Six-Fontaines', 4.0),\n ('Baulmes', 'Ste-Croix', 19.0),\n ('Six-Fontaines', 'Ste-Croix', 15.0)]\n```\n:::\n:::\n\n\nThis seems to be a train that goes from Yverdon-les-Bains to Ste-Croix. It stops in Vuiteboeuf, Baulmes, and Six-Fontaines before getting to Ste-Croix. There is an edge between every station and all its subsequent stations on that \"Fahrt\". This is exactly what we wanted.\n\nNow, we flatten the Pandas series of lists into one edgelist.\n\n::: {#c8f880bf .cell execution_count=8}\n``` {.python .cell-code}\n# Flatten the result into one edgelist.\nedgelist = [x for l in edges_series.values for x in l]\n\nprint(\"Number of edges:\", len(edgelist))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of edges: 1110834\n```\n:::\n:::\n\n\nThis edgelist contains over one million edges. Note, however, that many of them are duplicates as we looped over all \"Fahrten\" of a given day. As in [Part 1](../sbb_nw/index.qmd), we will now aggregate all duplicate edges, counting the number of connections and the average travel time between any two nodes.\n\n::: {#ec70350a .cell execution_count=9}\n``` {.python .cell-code}\n# Empty dict\nedges = {}\n\n# Loop over elements in edgelist\nfor i in edgelist:\n    # Create key\n    key = (i[0], i[1])\n    # Get previous entries in dict (if there are any)\n    prev = edges.get(key, (0, 0))\n    # Update values in dict\n    edges[key] = (prev[0] + 1, prev[1] + i[2])\n\n# Divide summed up travel times by number of trips\nedges = {k: (v[0], round(v[1]/v[0], 2)) for k, v in edges.items()}\n\nprint(\"Number of edges:\", len(edges))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of edges: 37951\n```\n:::\n:::\n\n\nWe are left with 37'951 directed and weighted edges that are currently stored in a dict called `edges`. Let's see how long it takes to get from Olten to Winterthur and how many connections there are on a given day:\n\n::: {#db7ff2b6 .cell execution_count=10}\n``` {.python .cell-code}\n# Test\nedges[(\"Olten\", \"Winterthur\")]\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n(25, 63.84)\n```\n:::\n:::\n\n\nI can travel from Olten to Winterthur 25 times per day (without having to change trains) and the trip takes a bit more than an hour.\n\nNow, we import the nodelist from [Part 1](../sbb_nw/index.qmd) so that we can replace the station names in the edges by the BPUIC identifiers.\n\n::: {#3108fc5b .cell execution_count=11}\n``` {.python .cell-code}\n# Load the nodelist.\nnodes = pd.read_csv(\"nodelist.csv\", sep = \";\")\n\n# Create a node dict with BPUIC as values\nnode_dict = dict(zip(nodes.STATION_NAME, nodes.BPUIC))\n```\n:::\n\n\nAfter changing all stations names to BPUIC numbers we create a dataframe that can then be exported as a CSV file. Yay, we're done!\n\n::: {#e5659f65 .cell execution_count=12}\n``` {.python .cell-code}\n# Transform edge dict to nested list and replace all station names with their BPUIC\nedges = [[node_dict[k[0]], node_dict[k[1]], v[0], v[1]] for k,v in edges.items()]\n\n# Create a dataframe\nedges = pd.DataFrame(edges, columns = ['BPUIC1','BPUIC2','NUM_CONNECTIONS','AVG_DURATION'])\n\n# Have a look\nedges.head()\n\n# Export edge list\n# edges.to_csv(\"edgelist_SoC.csv\", sep = ';', encoding = 'utf-8', index = False)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BPUIC1</th>\n      <th>BPUIC2</th>\n      <th>NUM_CONNECTIONS</th>\n      <th>AVG_DURATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8503000</td>\n      <td>8500010</td>\n      <td>88</td>\n      <td>63.81</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8503000</td>\n      <td>8500090</td>\n      <td>14</td>\n      <td>81.36</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8500010</td>\n      <td>8500090</td>\n      <td>67</td>\n      <td>6.07</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8500090</td>\n      <td>8500010</td>\n      <td>67</td>\n      <td>6.39</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8500090</td>\n      <td>8503000</td>\n      <td>10</td>\n      <td>100.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nYou can download the result here: <a href=\"edgelist_SoC.csv\" download>Edgelist space-of-changes (CSV)</a>.\n\n### Space-of-stations\n\nFor the *space-of-stations* graph representation we make use of the fact that the *space-of-stations* graph should be a subgraph of the *space-of-stops* graph that we extracted in [Part 1](../sbb_nw/index.qmd) with the latter containing additional edges that represent **shortcuts**. For example, the *space-of-stops* graph contains a directed edge from Olten to Basel SBB as there are nonstop trains between these two stations. However, there are also smaller, regional trains which stop at all stations in between. The key idea (also nicely shown by Kurant and Thiran) is to go through all edges in the *space-of-stops* graph and identify the ones that are shortcuts.\n\nWe first load the (*space-of-stops*) edgelist from [Part 1](../sbb_nw/index.qmd) and add the station names.\n\n::: {#d1106cf3 .cell execution_count=13}\n``` {.python .cell-code}\n# Load the space-of-stops edgelist.\nedges = pd.read_csv(\"edgelist.csv\", sep = \";\")\n\n# Create a node dict with station names as values.\nnode_dict = dict(zip(nodes.BPUIC, nodes.STATION_NAME))\n\n# Add actual station names.\nedges[\"STATION1\"] = [node_dict[v] for v in edges[\"BPUIC1\"]]\nedges[\"STATION2\"] = [node_dict[v] for v in edges[\"BPUIC2\"]]\n\n# Check out the dataframe.\nprint(edges.head())\n\nprint(\"Number of edges in space-of-stops representation:\", edges.shape[0])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    BPUIC1   BPUIC2  NUM_CONNECTIONS  AVG_DURATION      STATION1      STATION2\n0  8503000  8500010               36         54.00     Zürich HB     Basel SBB\n1  8500010  8500090               67          6.07     Basel SBB  Basel Bad Bf\n2  8500090  8500010               67          6.39  Basel Bad Bf     Basel SBB\n3  8500010  8503000               39         57.87     Basel SBB     Zürich HB\n4  8503424  8500090               17         73.18  Schaffhausen  Basel Bad Bf\nNumber of edges in space-of-stops representation: 4215\n```\n:::\n:::\n\n\nFor the *space-of-stations* representation, **undirected** edges make the most sense. Thus, we need to make the directed edges from the *space-of-stops* representation undirected and remove all duplicates that this introduces (e.g., 'Olten - Basel SBB' and 'Basel SBB - Olten'). With a little help by ChatGPT I found an elegant solution to achieve just that.\n\nMore concretely, we iterate over the zip object containing the node pairs of all edges. The `min()` and `max()` functions applied to the station names will sort the station names alphabetically so that, for example, 'Olten - Basel SBB' and 'Basel SBB - Olten' are both transformed to 'Basel SBB - Olten'. Finally, the `set()` function will get rid of all duplicates.\n\n::: {#0c8f789f .cell execution_count=14}\n``` {.python .cell-code}\n# Get a list of unique undirected edges.\nunique_undirected_edges = list(set((min(e1, e2), max(e1, e2)) for e1, e2 in zip(edges[\"STATION1\"], edges[\"STATION2\"])))\n\nprint(\"Number of unique undirected edges:\", len(unique_undirected_edges))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of unique undirected edges: 2154\n```\n:::\n:::\n\n\nThis step leaves us with 2'154 undirected, unique edges.\n\n#### Data preprocessing for improved efficiency\n\nIn order to make the procedure further below more efficient, we extract here all unique \"Fahrten\". More specifically, we create a dictionary `fahrten` with the sequence of station names as key and the `FAHRT_BEZEICHNER` as value. Note that if a sequence of station names already exists as a key in the dict, then the value belonging to that key will be overwritten with the new `FAHRT_BEZEICHNER` but that doesn't bother us since we just want to be able to extract one example \"Fahrt\" per unique sequence of stops.\n\n::: {#1874e836 .cell execution_count=15}\n``` {.python .cell-code}\n# Empty dict\nfahrten = {}\n\n# Loop over grouped df.\n# If the same key (sequence of stops) reappears, the value will be overwritte.\n# But that behavior is desired: we only want to keep one FAHRT_BEZEICHNER per key.\nfor fahrt, group in df.groupby('FAHRT_BEZEICHNER'):\n    fahrten[tuple(group['STATION_NAME'])] = fahrt\n\nprint(\"Number of unique 'Fahrten':\", len(fahrten))\nprint(\"Number of 'Fahrten' in whole dataframe:\", df['FAHRT_BEZEICHNER'].nunique())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of unique 'Fahrten': 1678\nNumber of 'Fahrten' in whole dataframe: 14653\n```\n:::\n:::\n\n\nWe can see from the above output that this step drastically reduces the \"Fahrten\" that we will iterate over later.\n\nIn the following code chunk we filter the \"Ist-Daten\" (`df`) loaded earlier so that only the unique \"Fahrten\" are left.\n\n::: {#f54ccf38 .cell execution_count=16}\n``` {.python .cell-code}\n# Reduce the dataframe to the 'Fahrten' in list of values of dict.\ndf = df[df['FAHRT_BEZEICHNER'].isin(list(fahrten.values()))]\n\nprint(\"Remaining number of rows:\", df.shape[0])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRemaining number of rows: 17597\n```\n:::\n:::\n\n\nAnother little trick to make things more efficent later is to create a dictionary with station names as keys and a list with all `FAHRT_BEZEICHNER` strings a station name is part of as values (kind of an *inverted index*).\n\n::: {#22cfa983 .cell execution_count=17}\n``` {.python .cell-code}\n# defaultdict with lists\nresult_dict = defaultdict(list)\n\n# Iterate over rows\nfor _, row in df.iterrows():\n    # Create a dict with stations as keys and FAHRT_BEZEICHNER as values.\n    result_dict[row['STATION_NAME']].append(row['FAHRT_BEZEICHNER'])\n\n# Convert back to normal dict.\nresult_dict = dict(result_dict)\n```\n:::\n\n\n#### Identify shortcuts\n\nNext, we perform the key step in extracting the edges for the *space-of-stations* representation: we need to identify all edges that are shortcuts, passing train stations without stopping.\n\nWe first define a custom function that determines whether any two station names `a` and `b` are adjacent in a sequence (list) of station names `lst`.\n\n::: {#a591f5d9 .cell execution_count=18}\n``` {.python .cell-code}\n# Function to check whether elements a and b are NOT adjacent in lst.\ndef is_shortcut(lst, a, b):\n    return not any((x, y) == (a, b) or (x, y) == (b, a) for x, y in zip(lst, lst[1:]))\n```\n:::\n\n\nThen, we iterate over all undirected, unique edges that we prepared above. For each edge we go through the following steps:\n\n1.  We get the `FAHRT_BEZEICHNER` strings for all \"Fahrten\" which both nodes of the edge are part of. For this we use the *inverted index*-style dictionary we created above.\n2.  Then we perform an inner loop over the \"Fahrten\" extracted in the first step.\n    -   We first extract the sequence of stations of a \"Fahrt\".\n    -   We use our custom function from above to check whether the two nodes are adjacent in the sequence of stations.\n    -   If they are not adjacent, i.e., the edge represents a shortcut, then we save that edge and break the inner loop and move on to the next edge.\n\n::: {#df3a1b22 .cell execution_count=19}\n``` {.python .cell-code}\n# Empty list for shortcuts.\nshortcut_edges = []\n\n# Loop over list of undirected edges.\nfor idx, edge in enumerate(unique_undirected_edges):\n    # Find all 'Fahrten' in which both stations of the edge appear.\n    intersection = list(set(result_dict[edge[0]]) & set(result_dict[edge[1]]))\n    # Initialize shortcut to False\n    shortcut = False\n    # Loop over 'Fahrten' in which both stations of the edge appear.\n    for fahrt in intersection:\n        # Get the sequence of stations in current 'Fahrt'.\n        seq_of_stations = df.loc[df['FAHRT_BEZEICHNER'] == fahrt, 'STATION_NAME'].tolist()\n        # Check whether the edge represents a shortcut in that sequence.\n        shortcut = is_shortcut(seq_of_stations, edge[0], edge[1])\n        # If it is a shortcut, we add it to the list and break the inner loop.\n        if shortcut:\n            # Add to list and break the loop.\n            shortcut_edges.append((fahrt, edge))\n            break\n\nprint(\"Number of shortcut edges:\", len(shortcut_edges))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of shortcut edges: 442\n```\n:::\n:::\n\n\nA total of 442 edges are identified as shortcuts. Let's have a look at the first one:\n\n::: {#1c795c71 .cell execution_count=20}\n``` {.python .cell-code}\n# Check first shortcut.\nprint(shortcut_edges[0])\n\n# Check the 'Fahrt' in which it was detected as a shortcut.\ndf.loc[df['FAHRT_BEZEICHNER'] == shortcut_edges[0][0], 'STATION_NAME']\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n('85:22:2076:000', ('Bühler', 'Gais'))\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\n1236                       Gais\n1237                Zweibrücken\n1238                 Strahlholz\n1239                     Bühler\n1240                  Steigbach\n1241                  Teufen AR\n1242           Teufen AR Stofel\n1243         Sternen bei Teufen\n1244               Niederteufen\n1245                  Lustmühle\n1246       St. Gallen Riethüsli\n1247    St. Gallen Güterbahnhof\n1248                 St. Gallen\n1249      St. Gallen Marktplatz\n1250       St. Gallen Spisertor\n1251     St. Gallen Schülerhaus\n1252      St. Gallen Birnbäumen\n1253      St. Gallen Notkersegg\n1254            Schwarzer Bären\n1255                Vögelinsegg\n1256             Schützengarten\n1257                   Speicher\n1258                   Bendlehn\n1259                      Gfeld\n1260                     Trogen\nName: STATION_NAME, dtype: object\n```\n:::\n:::\n\n\nFrom the whole sequence of stations, we can see that the edge identified as a shortcut is, in fact, a connection that is not consecutive.\n\nFinally, we remove the `FAHRT_BEZEICHNER` from `shortcut_edges` and create the final edge list without shortcuts.\n\n::: {#72326ebd .cell execution_count=21}\n``` {.python .cell-code}\n# Extract only edges\nshortcut_edges_clean = [i[1] for i in shortcut_edges]\n\n# Get the final list of non-shortcut edges.\nfinal_edges = [e for e in unique_undirected_edges if e not in shortcut_edges_clean]\n\nprint(\"Number of edges:\", len(final_edges))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of edges: 1712\n```\n:::\n:::\n\n\nWe have a final number of edges of $2154-442=1712$.\n\n#### Validate with \"Liniendaten\"\n\nThe extraction of the edges in the *space-of-stations* representation was a bit more complex than for *space-of-changes* or *space-of-stops*. That's why I would like to run some checks.\n\nWe can validate some of the edges we extracted with another dataset from the [Open Data Portal of SBB](https://data.sbb.ch/pages/home/). The dataset [Linie (Betriebspunkte)](https://data.sbb.ch/explore/dataset/linie-mit-betriebspunkten/information/) contains all railway \"lines\" maintained by SBB with all \"Betriebspunkte\" (including stations) that are located along these lines. Let's load this dataset:\n\n::: {#ed69e6bd .cell execution_count=22}\n``` {.python .cell-code}\n# Load the data about \"Linien mit Betriebspunkten\"\nlinien = pd.read_csv('linie-mit-betriebspunkten.csv', sep = \";\")\n\n# Reduce to relevant columns\nlinien = linien[[\"Name Haltestelle\",\"Linie\",\"KM\",\"Linien Text\",\"BPUIC\"]]\n\nprint(\"Shape of dataframe:\", linien.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nShape of dataframe: (1884, 5)\n```\n:::\n:::\n\n\nLet's have a look:\n\n::: {#d073d346 .cell execution_count=23}\n``` {.python .cell-code}\n# Have a look at the dataframe\nlinien.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name Haltestelle</th>\n      <th>Linie</th>\n      <th>KM</th>\n      <th>Linien Text</th>\n      <th>BPUIC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aarau</td>\n      <td>649</td>\n      <td>41.50577</td>\n      <td>Aarau - Woschnau Tunnel alt</td>\n      <td>8502113</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Aarberg</td>\n      <td>251</td>\n      <td>95.49304</td>\n      <td>Palezieux Est - Lyss Nord</td>\n      <td>8504404</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aesch BL</td>\n      <td>230</td>\n      <td>113.00006</td>\n      <td>Delemont Est - Basel SBB Ost</td>\n      <td>8500117</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Aespli</td>\n      <td>455</td>\n      <td>92.76586</td>\n      <td>Unterhard BE - Aespli</td>\n      <td>8515299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Aigle</td>\n      <td>100</td>\n      <td>39.31241</td>\n      <td>Lausanne - Simplon Tunnel I - Iselle</td>\n      <td>8501400</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe rows in that dataset are not just stations but also other \"Betriebspunkte\" (important locations that are needed to run the infrastructure). But we can identify the stations among the \"Betriebspunkte\" by joining the `nodes` dataframe on BPUIC and only keeping the entries for which there was a matching row in `nodes`.\n\n::: {#ba51572b .cell execution_count=24}\n``` {.python .cell-code}\n# Join the rows of nodelist based on BPUIC.\nlinien = pd.merge(linien, nodes[[\"BPUIC\",\"STATION_NAME\"]], on = 'BPUIC', how = 'left')\n\n# How many entries have a missing value aka are not stations?\nprint(\"Number of non-stations:\", linien[\"STATION_NAME\"].isna().sum())\n\n# Drop all rows that are not stations.\nlinien = linien.dropna(subset = [\"STATION_NAME\"])\n\nprint(\"Number of remaining rows:\", linien.shape[0])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of non-stations: 979\nNumber of remaining rows: 905\n```\n:::\n:::\n\n\nNext, we group the rows by `'Linie'` and sort them in ascending order by `'KM'` (where along the line is the \"Betriebspunkt\" located, in terms of kilometres) so that the stations for each line are sorted in the right order.\n\n::: {#04bc19e7 .cell execution_count=25}\n``` {.python .cell-code}\n# Function to sort entries within a group in ascending order of KM\ndef sort_data(group):\n    return group.sort_values('KM', ascending = True)\n\n# Sort for each group\nlinien_sorted = linien.groupby('Linie', group_keys=False).apply(sort_data)\n\n# Let's have a look at Linie 290.\nlinien_sorted.loc[linien_sorted['Linie'] == 290]\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name Haltestelle</th>\n      <th>Linie</th>\n      <th>KM</th>\n      <th>Linien Text</th>\n      <th>BPUIC</th>\n      <th>STATION_NAME</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1351</th>\n      <td>Ostermundigen</td>\n      <td>290</td>\n      <td>110.76500</td>\n      <td>Bern Wylerfeld - Thun</td>\n      <td>8507002</td>\n      <td>Ostermundigen</td>\n    </tr>\n    <tr>\n      <th>865</th>\n      <td>Gumligen</td>\n      <td>290</td>\n      <td>113.95844</td>\n      <td>Bern Wylerfeld - Thun</td>\n      <td>8507003</td>\n      <td>Gümligen</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>Rubigen</td>\n      <td>290</td>\n      <td>119.03812</td>\n      <td>Bern Wylerfeld - Thun</td>\n      <td>8507005</td>\n      <td>Rubigen</td>\n    </tr>\n    <tr>\n      <th>1333</th>\n      <td>Munsingen</td>\n      <td>290</td>\n      <td>122.13149</td>\n      <td>Bern Wylerfeld - Thun</td>\n      <td>8507006</td>\n      <td>Münsingen</td>\n    </tr>\n    <tr>\n      <th>695</th>\n      <td>Wichtrach</td>\n      <td>290</td>\n      <td>125.73250</td>\n      <td>Bern Wylerfeld - Thun</td>\n      <td>8507007</td>\n      <td>Wichtrach</td>\n    </tr>\n    <tr>\n      <th>892</th>\n      <td>Kiesen</td>\n      <td>290</td>\n      <td>128.30300</td>\n      <td>Bern Wylerfeld - Thun</td>\n      <td>8507008</td>\n      <td>Kiesen</td>\n    </tr>\n    <tr>\n      <th>1055</th>\n      <td>Uttigen</td>\n      <td>290</td>\n      <td>131.09513</td>\n      <td>Bern Wylerfeld - Thun</td>\n      <td>8507009</td>\n      <td>Uttigen</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe see here for one example (Line 290) that the stations are now nicely sorted in ascending order of `'KM'`.\n\nNow, we can create a new column that always contains the station name of the next row using the handy `shift()` method. The last row within a group will always have a missing value for that new column as there is no next station at the end of a line. So, we drop the last row of each line.\n\n::: {#010436b8 .cell execution_count=26}\n``` {.python .cell-code}\n# Create a new column that for each row contains the next stop within the group.\nlinien_sorted[\"NEXT_STATION\"] = linien_sorted.groupby(\"Linie\")[\"STATION_NAME\"].shift(-1)\n\n# Drop all rows where 'NEXT_STATION' is missing\nlinien_sorted = linien_sorted.dropna(subset = [\"NEXT_STATION\"])\n```\n:::\n\n\nWe extract the values of the last two columns as the edges. Importantly, we now sort the node pairs in each edge in the same way as before (alphabetically).\n\n::: {#19861a4b .cell execution_count=27}\n``` {.python .cell-code}\n# Now let's extract the edges\nlinien_edges = list(zip(linien_sorted['STATION_NAME'], linien_sorted['NEXT_STATION']))\n\n# Make sure the tuples are arranged in the same way as above (and unique).\nlinien_edges = list(set((min(e[0], e[1]), max(e[0], e[1])) for e in linien_edges))\n```\n:::\n\n\nWe first want to check whether there are edges in `linien_edges` that are neither a shortcut nor in the final edgelist from above.\n\n::: {#712230cd .cell execution_count=28}\n``` {.python .cell-code}\n# Check which edges are in linien_edges but neither in final_edges nor in shortcut_edges_clean.\n[x for x in linien_edges if x not in final_edges and x not in shortcut_edges_clean]\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\n[('Koblenz', 'Laufenburg'),\n ('La Chaux-de-Fonds', 'Tavannes'),\n ('Concise', 'Grandson'),\n ('Büren an der Aare', 'Solothurn'),\n ('Dietfurt', 'Kaltbrunn'),\n ('Neuhausen Rheinfall', 'Rafz'),\n ('Chambrelien', 'Corcelles-Peseux'),\n ('Bauma', 'Hinwil'),\n ('Niederbipp', 'Solothurn'),\n ('Langenthal', 'Niederbipp'),\n ('Solothurn', 'Zollikofen')]\n```\n:::\n:::\n\n\nThere are some candidate edges but I checked all of them manually in the train schedule and none of them seem to have direct train connections. It could be that some of these are old train lines that are not active anymore.\n\nAre there any edges in `linien_edges` that were classified as shortcuts?\n\n::: {#ea957c83 .cell execution_count=29}\n``` {.python .cell-code}\n# Are there any edges that I classified as shortcuts?\n[x for x in linien_edges if x in shortcut_edges_clean]\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\n[('Chur', 'Landquart'), ('Niederbipp', 'Oensingen')]\n```\n:::\n:::\n\n\nYes, but the two lines are in fact shortcuts. Between Niederbipp and Oensingen there is a small station called Niederbipp Industrie. Between Chur and Landquart there are several smaller stations. Note, however, that it could be that even though the train tracks between Chur and Landquart actually pass those smaller stations there is no infrastructure for trains to actually stop.\n\nA manual check of all 1'712 edges reveals that there are more shortcuts that our procedure was not able to identify. For example, the edge `(Bern, Zofingen)` cannot be identified because there is no other \"Fahrt\" that contains these two stations and stops somewhere in between. We manually remove such edges. In addition, we add some edges for which I know that there is actually infrastructure (tunnels, high-speed routes) that directly connects the two nodes involved.\n\n::: {#abc63148 .cell execution_count=30}\n``` {.python .cell-code}\n# Manually remove edges.\nfinal_edges.remove(('Bern', 'Zofingen'))\nfinal_edges.remove(('Bern Wankdorf', 'Zürich HB'))\nfinal_edges.remove(('Basel Bad Bf', 'Schaffhausen'))\n\n# Manually add edges.\nfinal_edges.append(('Biasca', 'Erstfeld'))\n# final_edges.append(('Frutigen', 'Visp')) # Seems to be already in there.\nfinal_edges.append(('Bern Wankdorf', 'Rothrist'))\n```\n:::\n\n\n#### Export the edgelist\n\nFinally, we can export the edges as before for the other representations.\n\n::: {#cd590166 .cell execution_count=31}\n``` {.python .cell-code}\n# Create a node dict with BPUIC as values\nnode_dict = dict(zip(nodes.STATION_NAME, nodes.BPUIC))\n\n# Transform edge dict to nested list and replace all station names with their BPUIC\nedges = [[node_dict[e[0]], node_dict[e[1]]] for e in final_edges]\n\n# Create a dataframe\nedges = pd.DataFrame(edges, columns = ['BPUIC1','BPUIC2'])\n\n# Have a look\nedges.head()\n\n# Export edge list\n# edges.to_csv(\"edgelist_SoS.csv\", sep = ';', encoding = 'utf-8', index = False)\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BPUIC1</th>\n      <th>BPUIC2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8501160</td>\n      <td>8501162</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8501067</td>\n      <td>8501068</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8500302</td>\n      <td>8500301</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8500113</td>\n      <td>8500114</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8501287</td>\n      <td>8501288</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nYou can download the result here: <a href=\"edgelist_SoS.csv\" download>Edgelist space-of-stations (CSV)</a>.\n\n### References\n\nKurant, M., & Thiran, P. (2006). Extraction and analysis of traffic and topologies of transportation networks. Physical Review E, 74(3), 036114. <https://doi.org/10.1103/PhysRevE.74.036114>\n\n*The title image has been created by Wikimedia user JoachimKohler-HB and is licensed under [Creative Commons](https://creativecommons.org/licenses/by-sa/4.0/deed.en).*\n\n",
    "supporting": [
      "index_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}